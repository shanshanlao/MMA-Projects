{"cells":[{"cell_type":"code","execution_count":212,"metadata":{},"outputs":[],"source":["# Loading libraries\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot"]},{"cell_type":"code","execution_count":213,"metadata":{},"outputs":[],"source":["# Import the dataset\n","kickstarter = pd.read_excel('Kickstarter.xlsx')"]},{"cell_type":"code","execution_count":214,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\shans\\AppData\\Local\\Temp\\ipykernel_27332\\2678655226.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['state'] = df['state'].replace(['successful','failed'],[1,0])\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>name</th>\n","      <th>goal</th>\n","      <th>pledged</th>\n","      <th>state</th>\n","      <th>disable_communication</th>\n","      <th>country</th>\n","      <th>currency</th>\n","      <th>deadline</th>\n","      <th>state_changed_at</th>\n","      <th>...</th>\n","      <th>created_at_day</th>\n","      <th>created_at_yr</th>\n","      <th>created_at_hr</th>\n","      <th>launched_at_month</th>\n","      <th>launched_at_day</th>\n","      <th>launched_at_yr</th>\n","      <th>launched_at_hr</th>\n","      <th>create_to_launch_days</th>\n","      <th>launch_to_deadline_days</th>\n","      <th>launch_to_state_change_days</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1601563193</td>\n","      <td>Our future</td>\n","      <td>100000000.0</td>\n","      <td>1.00</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>AU</td>\n","      <td>AUD</td>\n","      <td>2014-10-07 12:05:39</td>\n","      <td>2014-10-07 12:05:39</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2014</td>\n","      <td>21</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>2014</td>\n","      <td>12</td>\n","      <td>6</td>\n","      <td>60</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>880009511</td>\n","      <td>Elite: Dangerous</td>\n","      <td>1250000.0</td>\n","      <td>1578316.08</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>GB</td>\n","      <td>GBP</td>\n","      <td>2013-01-04 18:00:57</td>\n","      <td>2013-01-04 18:00:57</td>\n","      <td>...</td>\n","      <td>31</td>\n","      <td>2012</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>2012</td>\n","      <td>18</td>\n","      <td>5</td>\n","      <td>60</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>557230947</td>\n","      <td>Bring Reading Rainbow Back for Every Child, Ev...</td>\n","      <td>1000000.0</td>\n","      <td>5408916.95</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>US</td>\n","      <td>USD</td>\n","      <td>2014-07-02 14:00:00</td>\n","      <td>2014-07-02 14:00:11</td>\n","      <td>...</td>\n","      <td>22</td>\n","      <td>2014</td>\n","      <td>22</td>\n","      <td>5</td>\n","      <td>28</td>\n","      <td>2014</td>\n","      <td>8</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1966069095</td>\n","      <td>ARKYD: A Space Telescope for Everyone</td>\n","      <td>1000000.0</td>\n","      <td>1505366.60</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>US</td>\n","      <td>USD</td>\n","      <td>2013-06-30 21:00:00</td>\n","      <td>2013-06-30 21:00:34</td>\n","      <td>...</td>\n","      <td>10</td>\n","      <td>2012</td>\n","      <td>17</td>\n","      <td>5</td>\n","      <td>29</td>\n","      <td>2013</td>\n","      <td>10</td>\n","      <td>322</td>\n","      <td>32</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2083255961</td>\n","      <td>A Billion Pixels...</td>\n","      <td>100000000.0</td>\n","      <td>56.00</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>US</td>\n","      <td>USD</td>\n","      <td>2014-08-04 16:39:34</td>\n","      <td>2014-08-04 16:39:34</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2014</td>\n","      <td>16</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>2014</td>\n","      <td>16</td>\n","      <td>34</td>\n","      <td>60</td>\n","      <td>60</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 45 columns</p>\n","</div>"],"text/plain":["           id                                               name         goal  \\\n","0  1601563193                                         Our future  100000000.0   \n","1   880009511                                   Elite: Dangerous    1250000.0   \n","4   557230947  Bring Reading Rainbow Back for Every Child, Ev...    1000000.0   \n","5  1966069095              ARKYD: A Space Telescope for Everyone    1000000.0   \n","6  2083255961                                A Billion Pixels...  100000000.0   \n","\n","      pledged  state  disable_communication country currency  \\\n","0        1.00      0                  False      AU      AUD   \n","1  1578316.08      1                  False      GB      GBP   \n","4  5408916.95      1                  False      US      USD   \n","5  1505366.60      1                  False      US      USD   \n","6       56.00      0                  False      US      USD   \n","\n","             deadline    state_changed_at  ... created_at_day created_at_yr  \\\n","0 2014-10-07 12:05:39 2014-10-07 12:05:39  ...              1          2014   \n","1 2013-01-04 18:00:57 2013-01-04 18:00:57  ...             31          2012   \n","4 2014-07-02 14:00:00 2014-07-02 14:00:11  ...             22          2014   \n","5 2013-06-30 21:00:00 2013-06-30 21:00:34  ...             10          2012   \n","6 2014-08-04 16:39:34 2014-08-04 16:39:34  ...              1          2014   \n","\n","   created_at_hr  launched_at_month  launched_at_day  launched_at_yr  \\\n","0             21                  8                8            2014   \n","1             11                 11                5            2012   \n","4             22                  5               28            2014   \n","5             17                  5               29            2013   \n","6             16                  6                5            2014   \n","\n","  launched_at_hr  create_to_launch_days  launch_to_deadline_days  \\\n","0             12                      6                       60   \n","1             18                      5                       60   \n","4              8                     35                       35   \n","5             10                    322                       32   \n","6             16                     34                       60   \n","\n","   launch_to_state_change_days  \n","0                           60  \n","1                           60  \n","4                           35  \n","5                           32  \n","6                           60  \n","\n","[5 rows x 45 columns]"]},"execution_count":214,"metadata":{},"output_type":"execute_result"}],"source":["# For the purpose of this project, we only need to include projects with \"successful\" or \"failure\" state\n","df = kickstarter[kickstarter['state'].isin(['successful','failed'])]\n","\n","# Convert the target variable to binary\n","df['state'] = df['state'].replace(['successful','failed'],[1,0])\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check the number of rows and columns \n","df.shape"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 Detect Duplicated Records"]},{"cell_type":"code","execution_count":215,"metadata":{},"outputs":[],"source":["# Check if there is any duplicated records\n","df = df.drop_duplicates()"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2 Detect Missing Values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check if there is any missing values\n","missing_values = np.where(pd.isnull(df))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Identify the columns that contain missing values\n","df.columns[list(set(np.where(pd.isnull(df))[1]))]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Count the percentage of missing values\n","len(missing_values[0]) / df.shape[0]"]},{"cell_type":"markdown","metadata":{},"source":["The predictors might be important for our future prediction.\n","And the number of records that contains missing values isn't significant in this dataset.\n","Hence we drop the missing values."]},{"cell_type":"code","execution_count":216,"metadata":{},"outputs":[{"data":{"text/plain":["(12180, 45)"]},"execution_count":216,"metadata":{},"output_type":"execute_result"}],"source":["df = df.dropna()\n","df.shape"]},{"cell_type":"markdown","metadata":{},"source":["### 1.3 Drop out-of-scope predictors"]},{"cell_type":"markdown","metadata":{},"source":["According to the project instruction, we can only use the predictors \"that are available at the moment when a new project is launched.\"\n","Therefore, we do not need any predictors regarding 'states' of the project."]},{"cell_type":"code","execution_count":217,"metadata":{},"outputs":[],"source":["df = df.drop(columns = ['state_changed_at','state_changed_at_weekday','state_changed_at_month', 'state_changed_at_day', 'state_changed_at_yr','state_changed_at_hr','launch_to_state_change_days'])"]},{"cell_type":"markdown","metadata":{},"source":["The information about pledged, staff_pick, backers_count, spotlight wont be available at the moment when the project is launched. Therefore, we remove them as well."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df.drop(columns = ['pledged','usd_pledged','staff_pick','backers_count','spotlight'])"]},{"cell_type":"markdown","metadata":{},"source":["### 1.4 Identify unique identifiers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Number of unique values\n","df.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Note that disable_communication only have one unique value\n","# So it won't be useful for our prediction\n","df = df.drop(columns = ['disable_communication'])\n","\n","# we can drop [id, name, deadline, created_at, launched_at] as they are almost a unique identifier\n","df= df.drop(columns = ['id','name','deadline', 'created_at', 'launched_at'])"]},{"cell_type":"markdown","metadata":{},"source":["### 1.5 Detect collinearity between variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check if there is any collinearity between variables\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(26, 6))\n","heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n","heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);\n","plt.savefig('heatmap.png', dpi=300, bbox_inches='tight')"]},{"cell_type":"markdown","metadata":{},"source":["According to the correlation heatmap, following varaibles have high correlation:\n","- name_len and name_len_clean, \n","- blurb_len and blurb_len_clean,\n","- deadline_yr and created_at_yr and launched_at_yr\n","\n","For each pair, we only need to keep one of them."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df.drop(columns = ['name_len_clean','blurb_len_clean','created_at_yr', 'launched_at_yr'])"]},{"cell_type":"markdown","metadata":{},"source":["### 1.6 Handle Categorical Variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check variable types\n","df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For 'weekday' variables. convert them into numerical variable from 1-7\n","cols = ['deadline_weekday','created_at_weekday','launched_at_weekday']\n","df[cols] = df[cols].replace(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],[1,2,3,4,5,6,7])"]},{"cell_type":"markdown","metadata":{},"source":["Before dummifying the categorical variables, first see how many values each category has."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dummify the other categorical variables\n","df = pd.get_dummies(df, columns = ['country','currency','category'])"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df.loc[:,df.columns != 'state']\n","y = df['state']"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Using LASSO"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Standardize the predictors\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_std_lasso = scaler.fit_transform(X)\n","\n","## Run LASSO\n","from sklearn.linear_model import Lasso\n","lasso = Lasso(alpha=0.01)\n","model_lasso = lasso.fit(X_std_lasso,y)\n","\n","model_lasso.coef_\n","\n","test = pd.DataFrame(list(zip(X.columns,model_lasso.coef_)), columns = ['predictor','coefficient'])\n","test[abs(test['coefficient']) >= 0.01].sort_values(by = 'coefficient')"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 Using Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split the dataset\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=5)\n","\n","# Build the model\n","from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state = 0)\n","model_rf = rf.fit(X_train, y_train)\n","\n","# Print feature importance\n","pd.Series(model_rf.feature_importances_, index = X.columns).sort_values(ascending = False).plot(kind = 'bar',figsize = (14,6))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.Series(model_rf.feature_importances_, index = X.columns).sort_values(ascending = False)\n","model_rf.feature_importances_[model_rf.feature_importances_ > 0.01]"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Classification Models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using predictors found by Random Forest\n","#X = df[['goal','create_to_launch_days','name_len','launch_to_deadline_days','launched_at_hr',\n","# 'launched_at_day','created_at_day','created_at_hr','deadline_day','blurb_len',\n","# 'category_Web','created_at_month','deadline_month', 'launched_at_month','created_at_weekday',\n","# 'launched_at_weekday','launched_at_weekday','deadline_yr','category_Software','static_usd_rate',\n","# 'category_Plays','category_Festivals']]\n","\n","# Predictors found by LASSO\n","X = df[['category_Web','category_Software','category_Plays','name_len','launch_to_deadline_days','deadline_yr',\n"," 'category_Festivals','category_Musical','category_Shorts','category_Experimental','category_Places',\n"," 'category_Immersive', 'launched_at_hr']]\n","\n","# combine the top selections?\n","#X = df[['goal','create_to_launch_days','name_len','launch_to_deadline_days','launched_at_hr',\n","#    'launched_at_day','created_at_day','created_at_hr','deadline_day','blurb_len',\n","#    'category_Web','category_Software','category_Plays','name_len','launch_to_deadline_days','deadline_yr',\n","#    'category_Festivals','category_Musical','category_Shorts','category_Experimental','category_Places']] \n","\n","# X = df[['name_len','launch_to_deadline_days','category_Web','deadline_yr','category_Software','category_Plays','category_Festivals']]\n","\n","y = df[\"state\"]\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_std = scaler.fit_transform(X)\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size = 0.30, random_state = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### PCA\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=3)\n","\n","pca.fit(X_std)\n","X_new = pca.transform(X_std)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_new,y,test_size=0.30, random_state=5)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1 Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","lr = LogisticRegression(max_iter = 500)\n","model_logit = lr.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2 K-Nearest Neighbors"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","accuracy = 0\n","bestK = 0\n","for i in range (1,21):\n","    knn = KNeighborsClassifier(n_neighbors=i)\n","    model = knn.fit(X_train,y_train)\n","    y_test_pred = model.predict(X_test)\n","    if accuracy_score(y_test, y_test_pred) > accuracy:\n","        accuracy = accuracy_score(y_test, y_test_pred)\n","        bestK = i\n","    #print(\"k = \", i, \"accuracy =\", accuracy_score(y_test, y_test_pred))\n","\n","knn = KNeighborsClassifier(n_neighbors=bestK) #,  weights = 'distance')\n","model_knn = knn.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.3 CART"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","decisiontree = DecisionTreeClassifier(max_depth=10) # default is to grow a full tree\n","                                    # avoid overfitting\n","model_dt = decisiontree.fit(X_train,y_train)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.4 Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the model\n","from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state = 0, oob_score=True)\n","model_rf = rf.fit(X_train, y_train)\n","\n","model_rf.oob_score_"]},{"cell_type":"markdown","metadata":{},"source":["### 3.5 Gradient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","gbt = GradientBoostingClassifier(random_state = 0)\n","model_gbt = gbt.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.6 Artificial Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Find the optimal size of hidden layer\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_val_score\n","for i in range(1,21): \n","    model = MLPClassifier(hidden_layer_sizes=(i), max_iter = 1000, random_state=0)\n","    scores = cross_val_score(model, X=X_std, y=y, cv=10)\n","    print(i, \":\", np.average(scores))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.neural_network import MLPClassifier\n","model_ann = MLPClassifier(hidden_layer_sizes=(14), random_state=0)\n","model_mlp = model_ann.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Find the best hyper-parameter\n","from sklearn.model_selection import GridSearchCV\n","mlp = MLPClassifier(max_iter=5000, random_state=0)\n","\n","parameter = {'hidden_layer_sizes': range(1,22)}\n","grid_search = GridSearchCV(estimator = mlp, param_grid= parameter, \n","                           scoring = \"accuracy\", verbose=True)\n","model_mlp = grid_search.fit(X_std, y)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.7 Support Vector Machine"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Find the optimal gamma\n","from sklearn.svm import SVC\n","for i in range(1,11):\n","    svm_rbf = SVC(kernel = \"rbf\", random_state=0, C =0.5, gamma = i)\n","    model_rbf = svm_rbf.fit(X_train,y_train)\n","    scores = cross_val_score(model_rbf,X=X_test, y=y_test, cv=10)\n","    print(\"gamma = \",i,\", score = \", sum(scores)/len(scores))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the SVM model using a linear model\n","from sklearn.svm import SVC\n","svm = SVC(kernel=\"linear\", random_state=0, C=0.5, gamma = 3)\n","model_svm = svm.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["### Model Performance Comparison"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import metrics\n","\n","def model_metrics(model,X,y):\n","    y_pred = model.predict(X)\n","\n","    accuracy = metrics.accuracy_score(y, y_pred)\n","    precision = metrics.precision_score(y, y_pred)\n","    recall = metrics.recall_score(y, y_pred)\n","    f1_score = metrics.f1_score(y, y_pred)\n","\n","    model_metrics = [accuracy, precision, recall, f1_score]\n","    return model_metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_performance = {\n","    'Logitstic': model_metrics(model_logit,X_test,y_test),\n","    'KNN': model_metrics(model_knn,X_test,y_test),\n","\n","    'DecisionTree': model_metrics(model_dt,X_test,y_test),\n","    'RandomForest': model_metrics(model_rf,X_test,y_test),\n","    'GradientBoosting': model_metrics(model_gbt,X_test,y_test),\n","\n","    'ANN': model_metrics(model_ann,X_test,y_test),\n","    'SVM': model_metrics(model_svm,X_test,y_test)    \n","}\n","\n","pd.DataFrame.from_dict(model_performance, orient='index',columns = ['accuracy','percision','recall','f1_score'])"]},{"cell_type":"markdown","metadata":{},"source":["### Lazy Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import lazypredict\n","from lazypredict.Supervised import LazyClassifier\n","\n","clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n","models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n","\n","print(models)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Evaluation on Grading Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loading libraries\n","import pandas as pd\n","import numpy as np\n","\n","# Import the dataset\n","grading = pd.read_excel('Kickstarter-Grading-Sample.xlsx')\n","\n","# For the purpose of this project, we only need to include projects with \"successful\" or \"failure\" state\n","df_test = grading[grading['state'].isin(['successful','failed'])]\n","\n","# Data Preprocessing\n","df_test = df_test.dropna()\n","\n","### Drop out-of-scope predictors\n","df_test = df_test.drop(columns = ['state_changed_at','state_changed_at_weekday','state_changed_at_month', \n","'state_changed_at_day', 'state_changed_at_yr','state_changed_at_hr','launch_to_state_change_days',\n","'pledged','staff_pick','backers_count','spotlight','disable_communication',\n","'id','name','deadline', 'created_at', 'launched_at','usd_pledged','name_len_clean','created_at_yr', 'launched_at_yr'])\n","\n","### Handle Categorical Variables\n","cols = ['deadline_weekday','created_at_weekday','launched_at_weekday']\n","df_test[cols] = df_test[cols].replace(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],[1,2,3,4,5,6,7])\n","\n","# dummify the other categorical variables\n","df_test = pd.get_dummies(df_test, columns = ['country','currency','category'])\n","# or just drop them\n","#df = df.drop(columns = ['country','currency','category'])\n","\n","df_test['state'] = df_test['state'].replace(['successful','failed'],[1,0])\n","\n","\n","# Testing\n","#X_grade = df_test[['goal','create_to_launch_days','name_len','launch_to_deadline_days',\n","#'category_Web','category_Software','category_Plays','category_Festivals']]\n","\n","#X_grade = df_test[['goal','create_to_launch_days','name_len','launch_to_deadline_days',\n","#'launched_at_hr','launched_at_day','created_at_day','created_at_hr','deadline_day','blurb_len',\n","# 'category_Web','created_at_month','deadline_month','created_at_weekday','launched_at_weekday','deadline_yr',\n","# 'category_Software','static_usd_rate','category_Plays','category_Festivals','category_Hardware','category_Musical']]\n","\n","# X_grade = df_test[['category_Web','category_Software','category_Plays','name_len','launch_to_deadline_days','deadline_yr']] #,'category_Festivals','category_Musical']]\n","\n","X_grade = df_test[['category_Web','category_Software','category_Plays','name_len','launch_to_deadline_days','deadline_yr',\n"," 'category_Festivals','category_Musical','category_Shorts','category_Experimental','category_Places',\n"," 'category_Immersive', 'launched_at_hr']]\n","y_grade = df_test[\"state\"]\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_grade = scaler.fit_transform(X_grade)\n","\n","\n","### PCA\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=3)\n","pca.fit(X_std)\n","#X_grade = pca.transform(X_grade)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_performance = {\n","    'Logitstic': model_metrics(model_logit,X_grade,y_grade),\n","    'KNN': model_metrics(model_knn,X_grade,y_grade),\n","\n","    'DecisionTree': model_metrics(model_dt,X_grade,y_grade),\n","    'RandomForest': model_metrics(model_rf,X_grade,y_grade),\n","    'GradientBoosting': model_metrics(model_gbt,X_grade,y_grade),\n","\n","    'ANN': model_metrics(model_ann,X_grade,y_grade),\n","    'SVM': model_metrics(model_svm,X_grade,y_grade)\n","}\n","\n","pd.DataFrame.from_dict(test_performance, orient='index',columns = ['accuracy','percision','recall','f1_score'])"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"eb8d3085d426e5e8dee3252ffbadecffc2a8c816985f9d79249a1de42c265c0a"}}},"nbformat":4,"nbformat_minor":2}
